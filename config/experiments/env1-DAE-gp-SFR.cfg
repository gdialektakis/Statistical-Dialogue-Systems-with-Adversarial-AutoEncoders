# Error model: 0% error rate, addditive confscorer, uniform nbestgenerator
# User model: standard sampled params, sampled patience
# Masks: on

###### General parameters ######
[GENERAL]
domains = SFRestaurants
singledomain = True
tracedialog = 0
seed = 07051991

[exec_config]
configdir = _benchmarkpolicies/experiments/dae
logfiledir = _benchmarklogs/experiments/dae
numtrainbatches = 10
traindialogsperbatch = 300
numbatchtestdialogs =  300
numtestdialogs =  300
trainerrorrate = 0
testerrorrate  = 0
testeverybatch = True

trainsourceiteration = 0
#deleteprevpolicy = True

save_step = 300

autoencoder = true
transfer = false
transfer_autoencoder_type = dense_multi
autoencoder_type = dense_denoising

[logging]
usecolor = False
screen_level = results
file_level = results
file = auto

###### Environment parameters ######

[agent]
maxturns = 25

[usermodel]
usenewgoalscenarios = True
oldstylepatience = False
patience = 4,6
configfile = config/sampledUM.cfg

[errormodel]
nbestsize = 1
confusionmodel = RandomConfusions
nbestgeneratormodel = SampledNBestGenerator
confscorer = additive


[summaryacts]
maxinformslots = 5
informmask = True
requestmask = True
informcountaccepted = 4
byemask = True

###### Dialogue Manager parameters ######
[policy]
policydir = _benchmarkpolicies
belieftype = focus
useconfreq = False
learning = True
policytype = gp
startwithhello = False
inpolicyfile = auto
outpolicyfile = auto



[gppolicy]
kernel = polysort

[gpsarsa]
random = False
scale = 3
saveasprior = False
saveasnpy = False
numprior = 0
gamma = 1.0
sigma = 5.0
nu = 0.001

###### Evaluation parameters ######

[eval]
rewardvenuerecommended=0
penaliseallturns = True
wrongvenuepenalty = 0
notmentionedvaluepenalty = 0
successmeasure = objective
successreward = 20

